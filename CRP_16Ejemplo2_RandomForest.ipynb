{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CRP_16Ejemplo2_RandomForest.ipynb","provenance":[{"file_id":"1SyQr02LBuo8ZwGD9j4LSVKAG4y0e4-mV","timestamp":1576236676551}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qf1DmOMP72K6","colab_type":"text"},"source":["# **Random Forest**"]},{"cell_type":"markdown","metadata":{"id":"y0wXzj9g8MHs","colab_type":"text"},"source":["Importar las librerias"]},{"cell_type":"code","metadata":{"id":"iTPW0Wx6WjaP","colab_type":"code","colab":{}},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WAljxdNK8RU7","colab_type":"text"},"source":["Cargar la base de datos"]},{"cell_type":"code","metadata":{"id":"kZwEPIahXDPc","colab_type":"code","colab":{}},"source":["data_bc = load_breast_cancer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7J_cRCm68XMi","colab_type":"text"},"source":["Dividir la base de datos en entrenamiento y test"]},{"cell_type":"code","metadata":{"id":"g30TD8MiX600","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(data_bc.data, data_bc.target, random_state=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ChZYECux8rYD","colab_type":"text"},"source":["Construir el modelo y entrenarlo a partir de los datos"]},{"cell_type":"code","metadata":{"id":"LX8oevCPYLCf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1576243903272,"user_tz":300,"elapsed":557,"user":{"displayName":"Carlos Andres Madrigal Gonzalez","photoUrl":"","userId":"09724702270983160783"}},"outputId":"2cbbc4ef-3f5f-4b94-f388-e47d9b30b257"},"source":["clf = DecisionTreeClassifier()\n","\n","random_forest = RandomForestClassifier(n_estimators=100)\n","\n","random_forest.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"r5jLF7XJYb11","colab_type":"text"},"source":["Predicción"]},{"cell_type":"code","metadata":{"id":"OoR1dxmCYPXm","colab_type":"code","colab":{}},"source":["rf_predict=random_forest.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-U3BxhgdXZIw","colab_type":"text"},"source":["Medir el Desempeño"]},{"cell_type":"code","metadata":{"id":"PnSSf0eCYTvj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":234},"executionInfo":{"status":"ok","timestamp":1576243925213,"user_tz":300,"elapsed":303,"user":{"displayName":"Carlos Andres Madrigal Gonzalez","photoUrl":"","userId":"09724702270983160783"}},"outputId":"2643f7d1-1bee-4790-8f1c-d3dc67c8204c"},"source":["print ('Accuracy of RandomForest classifier')\n","print(classification_report(y_test, rf_predict, target_names=data_bc.target_names))\n","\n","dt_cm= confusion_matrix(y_test, rf_predict)\n","print('Confusion Matrix', data_bc.target_names)\n","print(dt_cm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of RandomForest classifier\n","              precision    recall  f1-score   support\n","\n","   malignant       0.92      0.92      0.92        53\n","      benign       0.96      0.96      0.96        90\n","\n","    accuracy                           0.94       143\n","   macro avg       0.94      0.94      0.94       143\n","weighted avg       0.94      0.94      0.94       143\n","\n","Confusion Matrix ['malignant' 'benign']\n","[[49  4]\n"," [ 4 86]]\n"],"name":"stdout"}]}]}